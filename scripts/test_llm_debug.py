#!/usr/bin/env python3
"""
LLMè°ƒè¯•åŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•LLMå®¢æˆ·ç«¯çš„åŸå§‹æ•°æ®æ‰“å°åŠŸèƒ½
"""
import sys
import os
import asyncio

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from infrastructure.llm.client import LLMClient
from infrastructure.mcp.client.manager import MCPManager


async def test_llm_debug_output():
    """æµ‹è¯•LLMè°ƒè¯•è¾“å‡ºåŠŸèƒ½"""
    print("ğŸš€ LLMè°ƒè¯•åŠŸèƒ½æµ‹è¯•")
    print("ğŸ¯ å°†æ‰“å°æ‰€æœ‰å‘é€ç»™LLMå’Œä»LLMæ¥æ”¶çš„åŸå§‹æ•°æ®")
    print("=" * 60)
    
    # åˆå§‹åŒ–MCPç®¡ç†å™¨ï¼ˆåŒ…å«æ‰“å°æœºå·¥å…·ï¼‰
    print("ğŸ“¡ åˆå§‹åŒ–MCPç®¡ç†å™¨...")
    mcp_manager = MCPManager()
    await mcp_manager.connect_all()
    
    # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆå¯ç”¨è°ƒè¯•æ¨¡å¼ï¼‰
    print("ğŸ”§ åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆè°ƒè¯•æ¨¡å¼å¼€å¯ï¼‰...")
    llm_client = LLMClient(mcp_manager=mcp_manager, debug=True)
    
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•1: ç®€å•å¯¹è¯ï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰")
    print("=" * 60)
    
    response = await llm_client.chat(
        message="ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
        system_prompt="ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹",
        enable_tools=False
    )
    
    print(f"\nâœ… å¯¹è¯å®Œæˆ: {response.success}")
    print(f"ğŸ“ å“åº”é•¿åº¦: {len(response.message)}å­—ç¬¦")
    
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•2: å¸¦å·¥å…·è°ƒç”¨çš„å¯¹è¯")
    print("=" * 60)
    
    response = await llm_client.chat(
        message="è¯·å¸®æˆ‘æ£€æŸ¥ä¸€ä¸‹æ‰“å°æœºçš„çŠ¶æ€",
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥è°ƒç”¨æ‰“å°æœºå·¥å…·æ¥å¸®åŠ©ç”¨æˆ·",
        enable_tools=True
    )
    
    print(f"\nâœ… å·¥å…·è°ƒç”¨å¯¹è¯å®Œæˆ: {response.success}")
    print(f"ğŸ“ å“åº”é•¿åº¦: {len(response.message)}å­—ç¬¦")
    if response.metadata.get("tools_used", 0) > 0:
        print(f"ğŸ”§ ä½¿ç”¨äº† {response.metadata['tools_used']} ä¸ªå·¥å…·")
    
    # æ¸…ç†
    await mcp_manager.disconnect_all()


async def test_simple_llm_call():
    """æµ‹è¯•ç®€å•çš„LLMè°ƒç”¨ï¼ˆä¸æ¶‰åŠMCPï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•3: çº¯LLMè°ƒç”¨ï¼ˆæ— MCPå·¥å…·ï¼‰")
    print("=" * 60)
    
    # ä¸ä½¿ç”¨MCPç®¡ç†å™¨çš„LLMå®¢æˆ·ç«¯
    llm_client = LLMClient(mcp_manager=None, debug=True)
    
    response = await llm_client.chat(
        message="1+1ç­‰äºå¤šå°‘ï¼Ÿ",
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹",
        enable_tools=False
    )
    
    print(f"\nâœ… çº¯LLMè°ƒç”¨å®Œæˆ: {response.success}")
    print(f"ğŸ“ å“åº”: {response.message}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” LLMè°ƒè¯•æ•°æ®è¾“å‡ºæµ‹è¯•")
    print("ğŸ’¡ æ­¤æµ‹è¯•å°†æ˜¾ç¤ºæ‰€æœ‰LLMäº¤äº’çš„åŸå§‹æ•°æ®")
    print("ğŸª åŒ…æ‹¬ï¼šå‘é€çš„æ¶ˆæ¯ã€å·¥å…·å®šä¹‰ã€å“åº”å†…å®¹ã€å·¥å…·è°ƒç”¨ç­‰\n")
    
    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    asyncio.run(test_llm_debug_output())
    asyncio.run(test_simple_llm_call())
    
    print("\n" + "=" * 60)
    print("ğŸ‰ LLMè°ƒè¯•åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    print("ğŸ“‹ ç°åœ¨ä½ å¯ä»¥çœ‹åˆ°æ‰€æœ‰LLMäº¤äº’çš„è¯¦ç»†åŸå§‹æ•°æ®")
    print("ğŸ”§ è°ƒè¯•ä¿¡æ¯åŒ…æ‹¬ï¼š")
    print("   - å‘é€ç»™LLMçš„æ¶ˆæ¯å†…å®¹")
    print("   - å·¥å…·å®šä¹‰å’Œå‚æ•°")
    print("   - LLMå“åº”çš„åŸå§‹æ•°æ®")
    print("   - MCPå·¥å…·è°ƒç”¨çš„è¯·æ±‚å’Œç»“æœ")
    print("   - å®Œæ•´å¯¹è¯å†å²")


if __name__ == "__main__":
    main()