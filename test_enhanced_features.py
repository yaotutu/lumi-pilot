#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºåŠŸèƒ½ï¼šå¯è§‚æµ‹æ€§ã€é”™è¯¯å¤„ç†ã€å·¥å…·å‚æ•°ç­‰
"""
import grpc
import json
from generated import lumi_pilot_pb2, lumi_pilot_pb2_grpc

def test_tool_call_with_observability():
    """æµ‹è¯•å·¥å…·è°ƒç”¨å’Œå¯è§‚æµ‹æ€§åŠŸèƒ½"""
    try:
        with grpc.insecure_channel('localhost:50051') as channel:
            client = lumi_pilot_pb2_grpc.LumiPilotServiceStub(channel)
            
            print("ğŸ”§ æµ‹è¯•å·¥å…·è°ƒç”¨å’Œå¯è§‚æµ‹æ€§...")
            request = lumi_pilot_pb2.ChatRequest(
                message="è¯·è°ƒç”¨æ‰“å°æœºçŠ¶æ€å·¥å…·æŸ¥çœ‹å½“å‰çŠ¶æ€"
            )
            
            response = client.Chat(request)
            
            if response.success:
                print("âœ… å·¥å…·è°ƒç”¨æˆåŠŸ")
                print(f"ğŸ“ AIå›å¤: {response.message}")
                
                # æ£€æŸ¥æ–°å¢çš„å¯è§‚æµ‹æ€§å­—æ®µ
                print(f"ğŸ†” Request ID: {response.metadata.request_id}")
                print(f"â±ï¸  LLMå»¶è¿Ÿ: {response.metadata.llm_latency:.2f}s")
                print(f"ğŸ› ï¸  å·¥å…·å»¶è¿Ÿ: {response.metadata.tool_latency:.2f}s")
                print(f"ğŸ”§ å·¥å…·è°ƒç”¨æ•°: {response.metadata.tools_used}")
                
                if hasattr(response.metadata, 'tool_call_ids') and response.metadata.tool_call_ids:
                    print(f"ğŸ”— å·¥å…·è°ƒç”¨IDs: {list(response.metadata.tool_call_ids)}")
                
                if hasattr(response.metadata, 'generation_params'):
                    params = response.metadata.generation_params
                    print(f"âš™ï¸  ç”Ÿæˆå‚æ•°: model={params.get('model', 'N/A')}, temp={params.get('temperature', 'N/A')}")
                
            else:
                print(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {response.error}")
                
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")

def test_normal_chat():
    """æµ‹è¯•æ™®é€šå¯¹è¯çš„å¯è§‚æµ‹æ€§"""
    try:
        with grpc.insecure_channel('localhost:50051') as channel:
            client = lumi_pilot_pb2_grpc.LumiPilotServiceStub(channel)
            
            print("\nğŸ’¬ æµ‹è¯•æ™®é€šå¯¹è¯...")
            request = lumi_pilot_pb2.ChatRequest(
                message="ä½ å¥½ï¼Œç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±"
            )
            
            response = client.Chat(request)
            
            if response.success:
                print("âœ… å¯¹è¯æˆåŠŸ")
                print(f"ğŸ“ AIå›å¤: {response.message[:100]}...")
                print(f"ğŸ†” Request ID: {response.metadata.request_id}")
                print(f"â±ï¸  å»¶è¿Ÿ: {response.metadata.llm_latency:.2f}s")
                print(f"ğŸ› ï¸  å·¥å…·è°ƒç”¨: {response.metadata.tools_used}")
            else:
                print(f"âŒ å¯¹è¯å¤±è´¥: {response.error}")
                
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")

if __name__ == "__main__":
    test_tool_call_with_observability()
    test_normal_chat()